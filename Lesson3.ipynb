{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* which models are best\n",
    "    * how fast are they ?\n",
    "    * how much memory they consume?\n",
    "    * how accurate they are ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/43.6 kB 682.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.6/43.6 kB 537.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: torch in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from timm) (2.3.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from timm) (0.18.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from timm) (6.0.1)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Downloading safetensors-0.4.3-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from huggingface_hub->timm) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from huggingface_hub->timm) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from huggingface_hub->timm) (24.0)\n",
      "Requirement already satisfied: requests in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from huggingface_hub->timm) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from huggingface_hub->timm) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from torch->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from torch->timm) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from torch->timm) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from torchvision->timm) (10.3.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->timm) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->timm) (2021.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\indhrna\\desktop\\ml_practical\\practical_deep_learning\\practical_deep_learning\\.venv\\lib\\site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.4/2.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.8/2.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.3 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.3 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
      "   ---------------------------------------- 0.0/401.3 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 194.6/401.3 kB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 368.6/401.3 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 401.3/401.3 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.9 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 163.8/287.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 287.9/287.9 kB 4.5 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface_hub, timm\n",
      "Successfully installed huggingface_hub-0.23.1 safetensors-0.4.3 timm-1.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\INDHRNA\\Desktop\\ML_Practical\\Practical_Deep_learning\\Practical_Deep_learning\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "import timm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='811712512' class='' max='811706944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [811712512/811706944 07:20&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "dls = ImageDataLoaders.from_name_funct('.',\n",
    "                                       get_image_files(path),\n",
    "                                       valid_pct=0.2,\n",
    "                                       seed=143,\n",
    "                                       label_func=RegexLabeller(pat=r'^([^/]+)_\\d+'),\n",
    "                                       item_tfms=Resize(224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls,\n",
    "                       resenet34, metrics=error_rate)\n",
    "learn.fine_tune(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could try a better model, based on this analysis. the convenext mdels work great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models('convnext*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls,\n",
    "                       'convnext_tiny_in22k',\n",
    "                       metrics=error_rate).to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
